---
title: "Crazy Raisins: A Raisin Classification Adventure"
authors:
  - Yasaman Baher
  - Shreya Kakachery
  - Eric Wong
jupyter: python3

format:
  html:
    toc: true
    toc-title: "Table of Contents"
    toc-depth: 3
    number-sections: true
    output-dir: ../docs
  pdf:
    toc: true
    toc-depth: 3
    number-sections: true
    output-dir: ../docs
output-file: index.html
bibliography: references.bib
---

```{python}
#| echo: false
import pandas as pd
from IPython.display import Markdown, display
from tabulate import tabulate
from ucimlrepo import fetch_ucirepo
import altair as alt
from hashlib import sha1
import numpy as np
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import cross_val_score, cross_validate, train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import pandera.pandas as pa
from pandera import Column, Check, DataFrameSchema
```


```{python}
#| echo: false
# Load the classification report CSV
report = pd.read_csv("../results/models/raisin_model_classification_report.csv", index_col=0)

# Extract accuracy and f1
accuracy = float(report.loc["accuracy", "precision"])
weighted_f1 = float(report.loc["weighted avg", "f1-score"])

accuracy = round(accuracy, 3)
weighted_f1 = round(weighted_f1, 3)
```



# Summary

In this project, we built a classification model using logistic regression to predict raisin varieties—Besni and Kecimen—based on morphological measurements extracted from digitized raisin images. Several of the size-related features, such as `Area`, `Perimeter`, `MajorAxisLength`, and `ConvexArea`, were found to be strongly correlated. This suggests redundancy among these predictors, whereas features like `Eccentricity` and `Extent` provide more distinct shape information that may help refine classification.

Our model achieved an accuracy of `{python} accuracy`  and a weighted F1 score of `{python} weighted_f1`, indicating strong and balanced performance across both classes. The similarity of these two metrics suggests that the class distribution is not heavily skewed. However, the correlation heatmap shows that size-based measurements dominate the feature set, which could cause the model to over-rely on redundant information and increase the risk of overfitting.

The confusion matrix reveals that while the model performs well overall, some misclassifications occur where the two raisin types have overlapping visual characteristics. This is expected in real-world applications, where similar shape profiles can blur the distinction between varieties.

This classifier has practical implications for quality control in agriculture and food processing, where automated classification could reduce labor costs, improve consistency, and minimize human error. At the same time, misclassifications highlight the need for caution in applications involving labeling or pricing decisions.

Future work may include investigating which features contribute most to the model’s decisions, incorporating additional measurements such as color or texture, and experimenting with alternative machine learning algorithms. Evaluating the model’s generalizability on new raisin batches is also essential to ensure it performs reliably beyond this dataset.


# Introduction

Raisins are dried grapes, and like their fresh counterparts, different varieties vary in taste, texture, sweetness, and appearance. Beyond being a common snack, raisins are associated with various health benefits, such as increased raisin consumption has been linked to improved diet quality and reduced appetite [@olmo2019raisins]. Accurately identifying raisin varieties can be useful in food processing, quality control, and consumer preference studies.

The dataset used in this project consists of morphological measurements extracted from images of 900 raisins belonging to the Besni and Kecimen varieties, obtained from the UCI Machine Learning Repository. Each sample includes seven numerical features describing the size and shape of a raisin.

## Background
Morphological measurements, such as area, perimeter, and axis lengths, capture important geometric properties that may distinguish different raisin types. Because these biological shapes vary naturally, analyzing their quantitative characteristics can reveal patterns that are not easily detectable by simple visual inspection.

## Motivation
Our goal is to determine whether raisin variety can be accurately predicted using these measured properties. If successful, this type of model could support automated inspection systems in agriculture and food processing, reduce human error, and help standardize quality control. This analysis also helps us understand which features are most informative and whether logistic regression is an appropriate model for this classification task.


# Methods

## Data

The dataset used in this project consists of digitized raisin images provided by İ̇lkay Çınar, Murat Koklu, and Şakir Taşdemir from Selçuk University [@cinar2019raisin]. The dataset is available through the UCI Machine Learning Repository and was imported using the ucimlrepo Python library. The data can be obtained from [[here](https://archive.ics.uci.edu/dataset/850/raisin)]. Each observation corresponds to a single raisin and includes seven numerical features capturing its morphological properties. Every raisin belongs to one of two varieties: Besni or Kecimen.


```{python}
#| echo: false
raisin = fetch_ucirepo(id=850)
```

```{python}
#| echo: false
df = pd.concat([raisin.data.features, raisin.data.targets], axis=1)
df["Area"] = df["Area"].astype(float)
df["ConvexArea"] = df["ConvexArea"].astype(float)
```


```{python}
#| echo: false
X = raisin.data.features     # the features (7 morphological measurements)  
y = raisin.data.targets      # the class labels (Kecimen vs Besni) 
```

A standard 75%/25% train–test split was used to create separate datasets for model training and evaluation

```{python}
#| echo: false
test_size = 0.25
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 123)
```

@tbl-info provides a high-level summary of the dataset structure:

```{python}
#| echo: false
#| label: tbl-info
#| tbl-cap: High-level summary of the features in the raisin dataset.

# import io
# buffer = io.StringIO()
# X.info(buf=buffer)
# info_text = buffer.getvalue()

# Markdown(f"`\n{info_text}\n`")

import pandas as pd

info = pd.DataFrame({
    "Column": X.columns,
    "Non-Null Count": X.notnull().sum(),
    "Dtype": X.dtypes
})

Markdown(info.to_markdown())


```


@tbl-describe provides the descriptive statistics for the numerical features:

```{python}
#| echo: false
#| label: tbl-describe
#| tbl-cap: Statistical summary of numerical features in the raisin dataset.

Markdown(X.describe().to_markdown())
```


## Analysis
The LogisticRegression algorithm was used to build the classification model to predict the species of a raisin given its measured shape properties. The data was split 75% into training set and 25% into test set. We obtained an accuracy of `{python} accuracy` with our model, indicating strong performance given the simplicity of the model.

All analysis, visualization, and modeling were conducted in Python [@python] using libraries such as pandas [@pandas], NumPy [@numpy], and scikit-learn [@scikit-learn].

# Exploratory Data Analysis

We began our EDA by visualizing the two major axis measurements. The scatterplot in @fig-measurement-scatterplot shows visible separation between the two raisin varieties based on these measurements.


![Scatterplot of the two major measurements.](../figures/eda_scatter_plot.png){#fig-measurement-scatterplot}


Next, the Pearson correlation matrix shown in @fig-pearson-corr-matrix reveals strong correlations among size-related features such as Area, Perimeter, and ConvexArea. These relationships suggest redundancy among size metrics and highlight the importance of including shape-based descriptors.


![Pearson correlation matrix of each numerical feature.](../figures/eda_correlation_heatmap.png){#fig-pearson-corr-matrix}


The dataset contains a nearly even number of Besni and Kecimen raisins, as shown in @fig-class-distribution. This balance is beneficial for classification performance because it reduces the risk of a model over-emphasizing one class.


![Class Distribution of Raisin Variety.](../figures/eda_class_distribution.png){#fig-class-distribution}


# Results 

The confusion matrix for the Logistic Regression classifier (@fig-logreg-conf-matrix) shows that the model performs strongly overall but exhibits slightly better performance for the Kecimen class. Misclassifications occur in both directions, suggesting that some raisins share similar morphological properties that make them difficult to distinguish.


![Confusion matrix of the LogisticRegression model.](../results/models/raisin_model_confusion_matrix.png){#fig-logreg-conf-matrix}


The feature coefficient plot (@fig-coefs-barplot) highlights which variables contribute most strongly to the model’s predictions. Since Logistic Regression coefficients reflect the importance of standardized features, the magnitude of each bar indicates how strongly that feature influences classification. Size-related features appear dominant, reinforcing earlier observations from the correlation matrix.

![Bar plot of Feature Coefficients.](../results/models/raisin_model_feature_importance.png){#fig-coefs-barplot}


The model had an accuracy of `{python} accuracy` and a weighted F1 score of `{python} weighted_f1`.

# Discussion

Overall, the Logistic Regression classifier was effective at distinguishing between Besni and Kecimen raisins, achieving high accuracy and balanced performance across classes. The results support the idea that size-based features, such as area, perimeter, and convex area, play a major role in classification. However, because these measurements are highly correlated, the model may rely too heavily on redundant information, which could limit generalizability.

The confusion matrix suggests that some samples possess overlapping characteristics that blur the distinction between varieties. This is expected because when two raisins share similar shape and size profiles, a linear classifier may struggle to separate them cleanly. Incorporating less correlated features such as texture, color, or weight could help the model capture subtle differences that the current dataset does not include.


Future improvements may include feature engineering to better capture non-linear relationships, training other models such as Random Forests and SVMs, and hyperparameter tuning if it is relevant for the chosen model. 

These findings indicate that while the current model performs well for basic classification, there is strong potential for further improvement with more sophisticated modeling techniques and a richer feature set.


# References


